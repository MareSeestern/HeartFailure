# -*- coding: utf-8 -*-
"""Heart_disease_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LFFv8-wZUW9qIY_Xe4kCZ0gNF77iP3XG
"""

# -*- coding: utf-8 -*-
"""
Created on Wed Aug 28 14:14:31 2019

@author: mario
"""
# Nötige Bibliotheken
import tensorflow as tf
from tensorflow import keras
from numpy.random import seed
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split 
import matplotlib.pyplot as plt

data=np.genfromtxt("dataset_vollstandig.csv",delimiter=",")  # Laden der .csv mit den Daten

data = pd.DataFrame(data[1:], columns = ["age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope","ca","thal","target"]) # Daten in einen Pandas Dataframe laden

data = pd.get_dummies(data, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca',"thal"]) # Dummy Spalten erstellen um Categorical Variables aufzuspalten

print(data.head()) # Erste fünf Patienten zur Übersicht printen

data["target"]=data["target"].replace(2, 1) # Es wird keine Unterscheidung gebraucht,
data["target"]=data["target"].replace(3, 1) # ob der Herzerkrankung heilbar ist oder nicht
data["target"]=data["target"].replace(4, 1)

labels=[]
x=[]

pd.options.display.max_columns = 50

# Sortieren von Labels und Daten
labels=data["target"]
x = data.drop(['target'], axis = 1)
x=np.array(x)
labels=np.array(labels)

# Test und Train Split
X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size = 0.1, random_state = 0)
print(X_train.shape,y_train.shape)



def visualization(history):
    
    # Plot training & validation accuracy values
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    plt.show()
    
    # Plot training & validation loss values
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    plt.show()

seed(1)  # Seed zum Reporduzieren der Ergebnisse




# Modell erstellen (Hyperparameter über systematische Hyperparameter Suche gefunden)
init='glorot_uniform'

model = keras.Sequential([     
    keras.layers.Flatten(), 
  
    keras.layers.Dense(40,kernel_initializer=init, activation=tf.nn.sigmoid), 
    keras.layers.Dense(20,kernel_initializer=init, activation=tf.nn.sigmoid), 
    keras.layers.Dense(10,kernel_initializer=init, activation=tf.nn.sigmoid),
    keras.layers.Dense(1,kernel_initializer=init, activation=tf.nn.sigmoid),   
    ]) 

optimizer=keras.optimizers.RMSprop()
model.compile(optimizer=optimizer, loss=keras.losses.mean_squared_error, metrics=['accuracy'])

history=model.fit(X_train,y_train,validation_split=0.2,batch_size=2, epochs=200) # Trainieren und speichern der Ergebnisse
model.summary() # Übersicht des Aufbau des Modells ausgeben

# Test Accuracy berechnen und printen
test_loss, test_acc = model.evaluate(X_test, y_test)   
print('Test accuracy:', test_acc) 
print('Test loss:', test_loss)    
visualization(history) # Visualisierung des Trainings Graphen

model.save('model.pb') # Modell speichern



